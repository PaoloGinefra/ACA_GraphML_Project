{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c9a3c61",
   "metadata": {},
   "source": [
    "# THIS IS A FAILED ATTEMPT TO BUILD A NOTEBOOK RUNNABLE ON KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda62b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pip install git+https://github.com/PaoloGinefra/ACA_GraphML_Project.git\n",
    "%pip install optuna-integration[pytorch_lightning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import psutil\n",
    "import gc\n",
    "from typing import Dict, Any, List, Tuple, Optional\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch Geometric\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# Optuna for hyperparameter optimization\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "# Weights & Biases for experiment tracking\n",
    "try:\n",
    "    import wandb\n",
    "    WANDB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WANDB_AVAILABLE = False\n",
    "    print(\"W&B not available - install with: pip install wandb\")\n",
    "\n",
    "# Kaggle Secrets (if available)\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    KAGGLE_SECRETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    KAGGLE_SECRETS_AVAILABLE = False\n",
    "    print(\"Kaggle secrets not available - running outside Kaggle environment\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "pl.seed_everything(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")\n",
    "print(f\"PyTorch Lightning version: {pl.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n",
    "print(f\"Weights & Biases available: {WANDB_AVAILABLE}\")\n",
    "print(f\"Kaggle Secrets available: {KAGGLE_SECRETS_AVAILABLE}\")\n",
    "\n",
    "# üìä W&B Configuration and Login\n",
    "print(\"üîß Setting up Weights & Biases...\")\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    \n",
    "    # Get W&B credentials from Kaggle secrets\n",
    "    user_secrets = UserSecretsClient()\n",
    "    \n",
    "    try:\n",
    "        WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "        WANDB_ENTITY = user_secrets.get_secret(\"WANDB_ENTITY\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not load W&B secrets: {e}\")\n",
    "        print(\"üí° Make sure you've added WANDB_API_KEY and WANDB_ENTITY to Kaggle secrets\")\n",
    "        raise\n",
    "\n",
    "    if not WANDB_API_KEY:\n",
    "        raise ValueError(\"WANDB_API_KEY not found in Kaggle secrets\")\n",
    "    \n",
    "    # Enhanced W&B login with better error handling\n",
    "    wandb.login(key=WANDB_API_KEY, force=True)  # Force re-login\n",
    "    \n",
    "    # Test W&B connection with a simple API call\n",
    "    api = wandb.Api()\n",
    "    user = api.viewer\n",
    "    print(f\"‚úÖ W&B login successful as {user.username}\")\n",
    "    \n",
    "    # Entity validation and debugging\n",
    "    print(f\"\\nüîç Entity Configuration:\")\n",
    "    print(f\"   Personal Username: {user.username}\")\n",
    "    print(f\"   Configured Entity: {WANDB_ENTITY if WANDB_ENTITY else 'Not set'}\")\n",
    "    \n",
    "    # Important: Entity should be organization name, not personal username\n",
    "    if WANDB_ENTITY == user.username:\n",
    "        print(f\"‚ö†Ô∏è  WARNING: Entity is set to personal username!\")\n",
    "        print(f\"   This often causes 403 'permission denied' errors.\")\n",
    "        print(f\"   Update WANDB_ENTITY to your organization/team name instead.\")\n",
    "    \n",
    "    # Configure W&B settings for better stability\n",
    "    import os\n",
    "    os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "    \n",
    "    # Define project configuration\n",
    "    PROJECT_NAME = \"graph-regression-optimization\"\n",
    "    \n",
    "    print(f\"üìã W&B Project: {PROJECT_NAME}\")\n",
    "    print(f\"üè¢ W&B Entity: {WANDB_ENTITY if WANDB_ENTITY else 'Default (not set)'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå W&B setup failed: {e}\")\n",
    "    error_msg = str(e).lower()\n",
    "    if \"permission denied\" in error_msg or \"403\" in error_msg:\n",
    "        print(\"\\nüí° SOLUTION for 403 Permission Denied Error:\")\n",
    "        print(\"   1. Check your W&B dashboard URL: https://wandb.ai/[ENTITY]/[PROJECT]\")\n",
    "        print(\"   2. The [ENTITY] part is what you need to use, not your username\")\n",
    "        print(\"   3. Update your Kaggle secret 'WANDB_ENTITY' with the organization name\")\n",
    "        print(\"   4. If you don't have an organization, create a personal project first\")\n",
    "    elif \"network\" in error_msg or \"connection\" in error_msg:\n",
    "        print(\"üí° Check your internet connection or try again later\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Secrets Management for Kaggle\n",
    "# Use Kaggle Secrets interface to set these values\n",
    "\n",
    "# Import Kaggle UserSecrets\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    import os\n",
    "    user_secrets = UserSecretsClient()\n",
    "\n",
    "    KAGGLE_SECRETS_AVAILABLE = True\n",
    "    print(\"‚úÖ Kaggle secrets interface available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Kaggle secrets not available - running outside Kaggle environment\")\n",
    "    KAGGLE_SECRETS_AVAILABLE = False\n",
    "    user_secrets = None\n",
    "\n",
    "# W&B Configuration (set these in Kaggle secrets)\n",
    "WANDB_API_KEY = None\n",
    "WANDB_PROJECT = 'zinc-graph-regression'  # Default project name\n",
    "WANDB_ENTITY = None\n",
    "\n",
    "if KAGGLE_SECRETS_AVAILABLE:\n",
    "    try:\n",
    "        WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "        print(\"‚úÖ W&B API key loaded from Kaggle secrets\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not load WANDB_API_KEY from secrets: {e}\")\n",
    "    \n",
    "    try:\n",
    "        WANDB_PROJECT = user_secrets.get_secret(\"WANDB_PROJECT\")\n",
    "        print(\"‚úÖ W&B project name loaded from Kaggle secrets\")\n",
    "    except Exception:\n",
    "        print(\"‚ÑπÔ∏è Using default W&B project name (WANDB_PROJECT not set in secrets)\")\n",
    "    \n",
    "    try:\n",
    "        WANDB_ENTITY = user_secrets.get_secret(\"WANDB_ENTITY\")\n",
    "        print(\"‚úÖ W&B entity loaded from Kaggle secrets\")\n",
    "    except Exception:\n",
    "        print(\"‚ÑπÔ∏è W&B entity not set in secrets (will use default)\")\n",
    "\n",
    "# Supabase Database Configuration\n",
    "# Expected secret: Complete PostgreSQL connection URL\n",
    "# Format: postgresql://postgres.{project_id}:{password}@{host}:{port}/{database}\n",
    "SUPABASE_DB_URL = None\n",
    "\n",
    "if KAGGLE_SECRETS_AVAILABLE:\n",
    "    try:\n",
    "        SUPABASE_DB_URL = user_secrets.get_secret(\"SUPABASE_URL\")\n",
    "        print(\"‚úÖ Supabase database URL loaded from Kaggle secrets\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not load SUPABASE_URL from secrets: {e}\")\n",
    "        print(\"‚ÑπÔ∏è If you want to use remote database, set SUPABASE_URL in Kaggle secrets\")\n",
    "        print(\"‚ÑπÔ∏è Format: postgresql://postgres.{project_id}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "# Initialize W&B if available and configured\n",
    "if WANDB_AVAILABLE and WANDB_API_KEY:\n",
    "    try:\n",
    "        # Enhanced W&B login with better error handling\n",
    "        wandb.login(key=WANDB_API_KEY, force=True)  # Force re-login\n",
    "        \n",
    "        # Test W&B connection with a simple API call\n",
    "        api = wandb.Api()\n",
    "        user = api.viewer\n",
    "        print(f\"‚úÖ W&B login successful as {user.username}\")\n",
    "        \n",
    "        # Configure W&B settings for better stability\n",
    "        # Use environment variables instead of wandb.settings (which doesn't exist)\n",
    "        import os\n",
    "        os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è W&B login failed: {e}\")\n",
    "        error_msg = str(e).lower()\n",
    "        if \"permission denied\" in error_msg:\n",
    "            print(\"üí° Try regenerating your W&B API key and updating Kaggle secrets\")\n",
    "        elif \"network\" in error_msg or \"connection\" in error_msg:\n",
    "            print(\"üí° Check your internet connection or try again later\")\n",
    "        else:\n",
    "            print(\"üí° Check your W&B API key in Kaggle secrets\")\n",
    "        \n",
    "        WANDB_API_KEY = None  # Disable W&B if login fails\n",
    "        print(\"üîÑ Continuing without W&B logging...\")\n",
    "else:\n",
    "    if not WANDB_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è W&B library not available\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è W&B not configured - set WANDB_API_KEY in Kaggle secrets\")\n",
    "        print(\"üí° To enable W&B logging:\")\n",
    "        print(\"   1. Go to https://wandb.ai/settings and copy your API key\")\n",
    "        print(\"   2. In Kaggle: Add-ons > Secrets > + Add Secret\")\n",
    "        print(\"   3. Label: WANDB_API_KEY, Value: your_api_key_here\")\n",
    "\n",
    "# Optuna study configuration\n",
    "STUDY_NAME = \"zinc-graph-regression-multiobj\"\n",
    "OPTUNA_DB_URL = SUPABASE_DB_URL  # Use the complete URL directly\n",
    "\n",
    "if OPTUNA_DB_URL:\n",
    "    print(\"‚úÖ Optuna remote database configured\")\n",
    "    print(f\"‚ÑπÔ∏è Database host: {OPTUNA_DB_URL.split('@')[1].split(':')[0] if '@' in OPTUNA_DB_URL else 'unknown'}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Remote database not configured - will use local SQLite\")\n",
    "    print(\"‚ÑπÔ∏è To use remote storage, set SUPABASE_DB_URL in Kaggle secrets\")\n",
    "\n",
    "# Global configuration\n",
    "CONFIG = {\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_trials': 50,  # Number of hyperparameter trials\n",
    "    'timeout_hours': 6,  # Kaggle notebook timeout consideration\n",
    "    'early_stopping_patience': 15,\n",
    "    'max_epochs': 100,\n",
    "    'val_check_interval': 1.0,  # Check validation every epoch\n",
    "    'log_every_n_steps': 10,\n",
    "}\n",
    "\n",
    "print(f\"\\nüìä Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Display configuration summary\n",
    "print(f\"\\nüîß Secrets Configuration Summary:\")\n",
    "print(f\"  Kaggle Secrets Available: {'‚úÖ' if KAGGLE_SECRETS_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"  W&B API Key: {'‚úÖ Configured' if WANDB_API_KEY else '‚ùå Not set'}\")\n",
    "print(f\"  W&B Project: {WANDB_PROJECT}\")\n",
    "print(f\"  W&B Entity: {WANDB_ENTITY if WANDB_ENTITY else 'Default (not set)'}\")\n",
    "print(f\"  Remote Database: {'‚úÖ Configured' if OPTUNA_DB_URL else '‚ùå Not set'}\")\n",
    "print(f\"  Study Name: {STUDY_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a17b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug and Production Mode Configuration\n",
    "# Set DEBUG_MODE = True for quick testing, False for full optimization\n",
    "\n",
    "DEBUG_MODE = False  # Change to True for testing\n",
    "\n",
    "if DEBUG_MODE:\n",
    "    print(\"üêõ DEBUG MODE ENABLED - Using reduced settings for testing\")\n",
    "    CONFIG.update({\n",
    "        'num_trials': 5,          # Reduced for testing\n",
    "        'timeout_hours': 0.5,     # 30 minutes for testing\n",
    "        'max_epochs': 15,         # Fewer epochs\n",
    "        'early_stopping_patience': 8,\n",
    "        'val_check_interval': 1.0,\n",
    "        'log_every_n_steps': 5,\n",
    "    })\n",
    "    BATCH_SIZE = 16  # Smaller batch size for testing\n",
    "    print(\"üìù Debug configuration applied\")\n",
    "else:\n",
    "    print(\"üöÄ PRODUCTION MODE - Full optimization settings\")\n",
    "\n",
    "print(f\"üìä Current Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"  batch_size: {BATCH_SIZE if 'BATCH_SIZE' in locals() else 32}\")\n",
    "\n",
    "# Environment validation\n",
    "def validate_environment():\n",
    "    \"\"\"Validate that the environment is properly configured.\"\"\"\n",
    "    checks = []\n",
    "    \n",
    "    # GPU Check\n",
    "    if torch.cuda.is_available():\n",
    "        checks.append((\"‚úÖ GPU\", f\"Available: {torch.cuda.get_device_name()}\"))\n",
    "    else:\n",
    "        checks.append((\"‚ö†Ô∏è GPU\", \"Not available - will use CPU (much slower)\"))\n",
    "    \n",
    "    # W&B Check\n",
    "    if WANDB_AVAILABLE and WANDB_API_KEY:\n",
    "        checks.append((\"‚úÖ W&B\", \"Configured and available\"))\n",
    "    else:\n",
    "        checks.append((\"‚ö†Ô∏è W&B\", \"Not configured - no experiment tracking\"))\n",
    "    \n",
    "    # Optuna DB Check\n",
    "    if OPTUNA_DB_URL:\n",
    "        checks.append((\"‚úÖ Optuna DB\", \"Remote database configured\"))\n",
    "    else:\n",
    "        checks.append((\"‚ö†Ô∏è Optuna DB\", \"Using local SQLite\"))\n",
    "    \n",
    "    # Memory Check\n",
    "    if torch.cuda.is_available():\n",
    "        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        checks.append((\"üìä GPU Memory\", f\"{total_memory:.1f} GB\"))\n",
    "    \n",
    "    print(\"\\nüîç Environment Validation:\")\n",
    "    for check_name, check_result in checks:\n",
    "        print(f\"  {check_name}: {check_result}\")\n",
    "    \n",
    "    return all(\"‚úÖ\" in check[0] for check in checks[:2])  # GPU and one of W&B/DB required\n",
    "\n",
    "# Run validation\n",
    "env_ok = validate_environment()\n",
    "if not env_ok:\n",
    "    print(\"\\n‚ö†Ô∏è Environment check completed with warnings. You can still proceed, but some features may be limited.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Environment validation passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd77078",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemMonitor:\n",
    "    \"\"\"\n",
    "    Comprehensive system monitoring for tracking memory, time, throughput and latency.\n",
    "    Designed for multi-objective optimization in Kaggle environment with robust error handling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset all tracking variables\"\"\"\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.peak_memory_mb = 0\n",
    "        self.initial_memory_mb = 0\n",
    "        self.samples_processed = 0\n",
    "        self.training_start_time = None\n",
    "        self.epoch_count = 0\n",
    "        \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"Start monitoring system metrics\"\"\"\n",
    "        try:\n",
    "            self.start_time = time.time()\n",
    "            self.training_start_time = time.time()\n",
    "            self.initial_memory_mb = self.get_current_memory_mb()\n",
    "            \n",
    "            # Reset peak memory tracking\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Warning: Could not start monitoring properly: {e}\")\n",
    "            self.start_time = time.time()  # At least track time\n",
    "        \n",
    "    def update_peak_memory(self):\n",
    "        \"\"\"Update peak memory usage\"\"\"\n",
    "        try:\n",
    "            current_memory = self.get_current_memory_mb()\n",
    "            self.peak_memory_mb = max(self.peak_memory_mb, current_memory)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Warning: Could not update memory tracking: {e}\")\n",
    "        \n",
    "    def get_current_memory_mb(self) -> float:\n",
    "        \"\"\"Get current memory usage in MB\"\"\"\n",
    "        try:\n",
    "            process = psutil.Process(os.getpid())\n",
    "            memory_info = process.memory_info()\n",
    "            \n",
    "            # CPU memory\n",
    "            cpu_memory_mb = memory_info.rss / 1024 / 1024\n",
    "            \n",
    "            # GPU memory if available\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_memory_mb = torch.cuda.memory_allocated() / 1024 / 1024\n",
    "                return max(cpu_memory_mb, gpu_memory_mb)  # Use the higher value\n",
    "            \n",
    "            return cpu_memory_mb\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Warning: Could not get memory usage: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def record_batch_processed(self, batch_size: int):\n",
    "        \"\"\"Record that a batch was processed\"\"\"\n",
    "        self.samples_processed += batch_size\n",
    "        self.update_peak_memory()\n",
    "    \n",
    "    def record_epoch_completed(self):\n",
    "        \"\"\"Record that an epoch was completed\"\"\"\n",
    "        self.epoch_count += 1\n",
    "    \n",
    "    def get_metrics(self) -> Dict[str, float]:\n",
    "        \"\"\"Get comprehensive system metrics\"\"\"\n",
    "        if self.start_time is None:\n",
    "            return {\n",
    "                'training_time_minutes': 0.0,\n",
    "                'memory_consumption_mb': 0.0,\n",
    "                'peak_memory_mb': 0.0,\n",
    "                'throughput_samples_per_sec': 0.0,\n",
    "                'latency_ms_per_sample': float('inf'),\n",
    "                'samples_processed': 0,\n",
    "                'epochs_completed': 0,\n",
    "            }\n",
    "            \n",
    "        try:\n",
    "            current_time = time.time()\n",
    "            elapsed_time = current_time - self.start_time\n",
    "            \n",
    "            # Memory metrics\n",
    "            current_memory_mb = self.get_current_memory_mb()\n",
    "            memory_consumption_mb = max(0, current_memory_mb - self.initial_memory_mb)\n",
    "            \n",
    "            # Performance metrics\n",
    "            throughput = self.samples_processed / elapsed_time if elapsed_time > 0 else 0\n",
    "            latency_ms = (elapsed_time * 1000) / self.samples_processed if self.samples_processed > 0 else float('inf')\n",
    "            \n",
    "            # Additional metrics\n",
    "            epochs_per_minute = (self.epoch_count / elapsed_time * 60) if elapsed_time > 0 else 0\n",
    "            \n",
    "            return {\n",
    "                'training_time_minutes': elapsed_time / 60,\n",
    "                'memory_consumption_mb': memory_consumption_mb,\n",
    "                'peak_memory_mb': self.peak_memory_mb,\n",
    "                'current_memory_mb': current_memory_mb,\n",
    "                'throughput_samples_per_sec': throughput,\n",
    "                'latency_ms_per_sample': latency_ms,\n",
    "                'samples_processed': self.samples_processed,\n",
    "                'epochs_completed': self.epoch_count,\n",
    "                'epochs_per_minute': epochs_per_minute,\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Warning: Could not calculate metrics: {e}\")\n",
    "            return {\n",
    "                'training_time_minutes': 0.0,\n",
    "                'memory_consumption_mb': 0.0,\n",
    "                'peak_memory_mb': 0.0,\n",
    "                'throughput_samples_per_sec': 0.0,\n",
    "                'latency_ms_per_sample': float('inf'),\n",
    "                'samples_processed': self.samples_processed,\n",
    "                'epochs_completed': self.epoch_count,\n",
    "            }\n",
    "    \n",
    "    def log_metrics(self, prefix: str = \"\"):\n",
    "        \"\"\"Log current metrics\"\"\"\n",
    "        try:\n",
    "            metrics = self.get_metrics()\n",
    "            print(f\"üìä {prefix} System Metrics:\")\n",
    "            \n",
    "            # Group metrics for better readability\n",
    "            time_metrics = {k: v for k, v in metrics.items() if 'time' in k or 'latency' in k}\n",
    "            memory_metrics = {k: v for k, v in metrics.items() if 'memory' in k}\n",
    "            performance_metrics = {k: v for k, v in metrics.items() if 'throughput' in k or 'samples' in k or 'epochs' in k}\n",
    "            \n",
    "            # Time metrics\n",
    "            for key, value in time_metrics.items():\n",
    "                if 'latency' in key:\n",
    "                    print(f\"  {key}: {value:.2f} ms\")\n",
    "                else:\n",
    "                    print(f\"  {key}: {value:.2f}\")\n",
    "            \n",
    "            # Memory metrics\n",
    "            for key, value in memory_metrics.items():\n",
    "                print(f\"  {key}: {value:.1f} MB\")\n",
    "            \n",
    "            # Performance metrics\n",
    "            for key, value in performance_metrics.items():\n",
    "                if 'throughput' in key:\n",
    "                    print(f\"  {key}: {value:.1f}\")\n",
    "                elif 'epochs_per_minute' in key:\n",
    "                    print(f\"  {key}: {value:.2f}\")\n",
    "                else:\n",
    "                    print(f\"  {key}: {value}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not log metrics: {e}\")\n",
    "\n",
    "# Create global monitor instance\n",
    "system_monitor = SystemMonitor()\n",
    "print(\"‚úÖ Enhanced system monitoring initialized\")\n",
    "\n",
    "# Test the monitor to ensure it's working\n",
    "try:\n",
    "    test_memory = system_monitor.get_current_memory_mb()\n",
    "    print(f\"üìä Current memory usage: {test_memory:.1f} MB\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Warning: System monitor test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23825db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "from ACAgraphML.Dataset import ZINC_Dataset\n",
    "from ACAgraphML.Transforms import OneHotEncodeFeat\n",
    "from ACAgraphML.Pipeline import DataAugmenter\n",
    "from ACAgraphML.Transforms import SteadyStateTransform\n",
    "from torch_geometric.transforms import AddRandomWalkPE\n",
    "\n",
    "# Constants for ZINC dataset\n",
    "NUM_NODE_FEATS = 28\n",
    "NUM_EDGE_FEATS = 4\n",
    "BATCH_SIZE = 32  # Optimized for Kaggle GPU memory\n",
    "\n",
    "def prepare_zinc_data():\n",
    "    \"\"\"\n",
    "    Prepare ZINC dataset with data augmentation and proper validation split.\n",
    "    Returns train, validation dataloaders and target statistics.\n",
    "    \"\"\"\n",
    "    print(\"üîÑ Loading ZINC dataset...\")\n",
    "    \n",
    "    # Define transforms\n",
    "    oneHotTransform = OneHotEncodeFeat(NUM_NODE_FEATS)\n",
    "    \n",
    "    def data_transform(data):\n",
    "        \"\"\"Complete data transformation pipeline\"\"\"\n",
    "        # Apply one-hot encoding\n",
    "        data = oneHotTransform(data)\n",
    "        \n",
    "        # Ensure proper data types\n",
    "        data.x = data.x.float()\n",
    "        \n",
    "        # Handle edge attributes\n",
    "        if data.edge_attr is not None:\n",
    "            if data.edge_attr.dim() == 1:\n",
    "                # Convert to one-hot if needed\n",
    "                data.edge_attr = torch.nn.functional.one_hot(\n",
    "                    data.edge_attr.long(),\n",
    "                    num_classes=NUM_EDGE_FEATS\n",
    "                ).float()\n",
    "            data.edge_attr = data.edge_attr.float()\n",
    "        \n",
    "        # Ensure target is float\n",
    "        if data.y is not None:\n",
    "            data.y = data.y.float()\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    # Load datasets - using subset for Kaggle time constraints\n",
    "    train_dataset = ZINC_Dataset.SMALL_TRAIN.load(transform=data_transform)\n",
    "    val_dataset = ZINC_Dataset.SMALL_VAL.load(transform=data_transform)\n",
    "    test_dataset = ZINC_Dataset.SMALL_TEST.load(transform=data_transform)\n",
    "    \n",
    "    print(f\"üìä Dataset sizes:\")\n",
    "    print(f\"  Training: {len(train_dataset)}\")\n",
    "    print(f\"  Validation: {len(val_dataset)}\")\n",
    "    print(f\"  Test: {len(test_dataset)}\")\n",
    "    \n",
    "    # Calculate target statistics for normalization\n",
    "    train_targets = torch.cat([data.y for data in train_dataset])\n",
    "    val_targets = torch.cat([data.y for data in val_dataset])\n",
    "    all_targets = torch.cat([train_targets, val_targets])\n",
    "    \n",
    "    target_mean = torch.mean(all_targets).item()\n",
    "    target_std = torch.std(all_targets).item()\n",
    "    \n",
    "    print(f\"üìà Target statistics:\")\n",
    "    print(f\"  Mean: {target_mean:.4f}\")\n",
    "    print(f\"  Std: {target_std:.4f}\")\n",
    "    print(f\"  Min: {torch.min(all_targets).item():.4f}\")\n",
    "    print(f\"  Max: {torch.max(all_targets).item():.4f}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    # Sample batch for inspection\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(f\"üîç Sample batch info:\")\n",
    "    print(f\"  Node features shape: {sample_batch.x.shape}\")\n",
    "    print(f\"  Edge features shape: {sample_batch.edge_attr.shape}\")\n",
    "    print(f\"  Targets shape: {sample_batch.y.shape}\")\n",
    "    print(f\"  Batch size: {sample_batch.y.shape[0]}\")\n",
    "    \n",
    "    return {\n",
    "        'train_loader': train_loader,\n",
    "        'val_loader': val_loader,\n",
    "        'test_loader': test_loader,\n",
    "        'target_mean': target_mean,\n",
    "        'target_std': target_std,\n",
    "        'num_train_samples': len(train_dataset),\n",
    "        'num_val_samples': len(val_dataset),\n",
    "        'num_test_samples': len(test_dataset),\n",
    "    }\n",
    "\n",
    "# Prepare data\n",
    "data_info = prepare_zinc_data()\n",
    "print(\"‚úÖ Data preparation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ba0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Objective Optimization Setup\n",
    "from ACAgraphML.Pipeline.LightningModules.GDLPipelineLighningModule import (\n",
    "    GDLPipelineLightningModule,\n",
    "    create_lightning_custom\n",
    ")\n",
    "from ACAgraphML.Pipeline.Models.GDLPipeline import (\n",
    "    GNNConfig,\n",
    "    PoolingConfig, \n",
    "    RegressorConfig\n",
    ")\n",
    "\n",
    "class MultiObjectiveCallback(pl.Callback):\n",
    "    \"\"\"\n",
    "    Custom callback to track system metrics during training.\n",
    "    Integrates with our SystemMonitor for comprehensive tracking.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, system_monitor: SystemMonitor):\n",
    "        super().__init__()\n",
    "        self.system_monitor = system_monitor\n",
    "        \n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        self.system_monitor.start_monitoring()\n",
    "        \n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        # Record batch processing\n",
    "        try:\n",
    "            batch_size = batch.y.shape[0] if hasattr(batch, 'y') else len(batch)\n",
    "            self.system_monitor.record_batch_processed(batch_size)\n",
    "        except Exception:\n",
    "            pass  # Skip if batch size cannot be determined\n",
    "        \n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        # Record validation batch processing\n",
    "        try:\n",
    "            batch_size = batch.y.shape[0] if hasattr(batch, 'y') else len(batch)\n",
    "            self.system_monitor.record_batch_processed(batch_size)\n",
    "        except Exception:\n",
    "            pass  # Skip if batch size cannot be determined\n",
    "\n",
    "def create_model_with_config(trial: optuna.Trial, data_info: Dict[str, Any]) -> GDLPipelineLightningModule:\n",
    "    \"\"\"\n",
    "    Create a GDL Pipeline model with hyperparameters suggested by Optuna.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object for hyperparameter suggestions\n",
    "        data_info: Dictionary containing dataset information and statistics\n",
    "        \n",
    "    Returns:\n",
    "        Configured GDLPipelineLightningModule\n",
    "    \"\"\"\n",
    "    \n",
    "    # Core architecture hyperparameters with fallback\n",
    "    if hasattr(trial, 'suggest_categorical'):\n",
    "        hidden_dim = trial.suggest_categorical('hidden_dim', [64, 128, 256, 512])\n",
    "        layer_name = trial.suggest_categorical('layer_name', [\n",
    "            'GCN', 'GAT', 'GATv2', 'SAGE', 'GINEConv', 'GINConv', 'PNA'\n",
    "        ])\n",
    "        pooling_type = trial.suggest_categorical('pooling_type', [\n",
    "            'mean', 'max', 'attentional', 'set2set'\n",
    "        ])\n",
    "        regressor_type = trial.suggest_categorical('regressor_type', [\n",
    "            'linear', 'mlp', 'residual_mlp', 'attention_mlp'\n",
    "        ])\n",
    "    else:\n",
    "        hidden_dim = trial.params.get('hidden_dim', 128)\n",
    "        layer_name = trial.params.get('layer_name', 'GCN')\n",
    "        pooling_type = trial.params.get('pooling_type', 'mean')\n",
    "        regressor_type = trial.params.get('regressor_type', 'mlp')\n",
    "    \n",
    "    if hasattr(trial, 'suggest_int'):\n",
    "        num_layers = trial.suggest_int('num_layers', 3, 6)\n",
    "    else:\n",
    "        num_layers = trial.params.get('num_layers', 3)\n",
    "    \n",
    "    # Regularization hyperparameters with fallback\n",
    "    if hasattr(trial, 'suggest_float'):\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.4)\n",
    "        global_dropout = trial.suggest_float('global_dropout', 0.0, 0.3)\n",
    "    else:\n",
    "        dropout_rate = trial.params.get('dropout_rate', 0.2)\n",
    "        global_dropout = trial.params.get('global_dropout', 0.1)\n",
    "    \n",
    "    # MLP specific parameters (if applicable)\n",
    "    if regressor_type != 'linear':\n",
    "        # Use integer choice to avoid dynamic value space issues\n",
    "        # Handle fallback for older trials that don't have regressor_choice\n",
    "        if hasattr(trial, 'suggest_int') and not hasattr(trial, 'params'):\n",
    "            # New trials - use regressor_choice\n",
    "            regressor_choice = trial.suggest_int('regressor_choice', 0, 2)\n",
    "            if regressor_choice == 0:\n",
    "                regressor_hidden_dims = [hidden_dim//2]\n",
    "            elif regressor_choice == 1:\n",
    "                regressor_hidden_dims = [hidden_dim, hidden_dim//2]\n",
    "            else:  # regressor_choice == 2\n",
    "                regressor_hidden_dims = [hidden_dim, hidden_dim//2, hidden_dim//4]\n",
    "        elif hasattr(trial, 'params') and 'regressor_choice' in trial.params:\n",
    "            # Evaluating old trial with regressor_choice\n",
    "            regressor_choice = trial.params['regressor_choice']\n",
    "            regressor_choices = {\n",
    "                0: [hidden_dim//2],\n",
    "                1: [hidden_dim, hidden_dim//2], \n",
    "                2: [hidden_dim, hidden_dim//2, hidden_dim//4]\n",
    "            }\n",
    "            regressor_hidden_dims = regressor_choices[regressor_choice]\n",
    "        elif hasattr(trial, 'params') and 'regressor_hidden_dims' in trial.params:\n",
    "            # Very old trials that had regressor_hidden_dims directly\n",
    "            regressor_hidden_dims = trial.params['regressor_hidden_dims']\n",
    "        else:\n",
    "            # Fallback for any other case\n",
    "            regressor_hidden_dims = [hidden_dim, hidden_dim//2]\n",
    "        \n",
    "        if hasattr(trial, 'suggest_float'):\n",
    "            mlp_dropout = trial.suggest_float('mlp_dropout', 0.0, 0.3)\n",
    "        else:\n",
    "            mlp_dropout = trial.params.get('mlp_dropout', 0.1)\n",
    "    else:\n",
    "        regressor_hidden_dims = []\n",
    "        mlp_dropout = 0.0\n",
    "    \n",
    "    # Optimization hyperparameters with fallback\n",
    "    if hasattr(trial, 'suggest_categorical'):\n",
    "        optimizer = trial.suggest_categorical('optimizer', ['adam', 'adamw', 'sgd'])\n",
    "        lr_scheduler = trial.suggest_categorical('lr_scheduler', [\n",
    "            'cosine', 'plateau', 'step', 'none'\n",
    "        ])\n",
    "        use_batch_norm = trial.suggest_categorical('use_batch_norm', [True, False])\n",
    "    else:\n",
    "        optimizer = trial.params.get('optimizer', 'adam')\n",
    "        lr_scheduler = trial.params.get('lr_scheduler', 'cosine')\n",
    "        use_batch_norm = trial.params.get('use_batch_norm', True)\n",
    "    \n",
    "    if hasattr(trial, 'suggest_float'):\n",
    "        lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "        weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "        gradient_clip_val = trial.suggest_float('gradient_clip_val', 0.5, 2.0)\n",
    "    else:\n",
    "        lr = trial.params.get('lr', 1e-3)\n",
    "        weight_decay = trial.params.get('weight_decay', 1e-4)\n",
    "        gradient_clip_val = trial.params.get('gradient_clip_val', 1.0)\n",
    "    \n",
    "    # Create configuration objects\n",
    "    gnn_config = GNNConfig(\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        layer_name=layer_name,\n",
    "        dropout_rate=dropout_rate,\n",
    "        use_residual=True,  # Always use residual connections\n",
    "        use_layer_norm=True,  # Always use layer normalization\n",
    "    )\n",
    "    \n",
    "    pooling_config = PoolingConfig(\n",
    "        pooling_type=pooling_type,\n",
    "        processing_steps=3 if pooling_type == 'set2set' else 3,\n",
    "        attention_hidden_multiplier=1.0 if pooling_type == 'attentional' else 1.0\n",
    "    )\n",
    "    \n",
    "    regressor_config = RegressorConfig(\n",
    "        regressor_type=regressor_type,\n",
    "        hidden_dims=regressor_hidden_dims,\n",
    "        mlp_dropout=mlp_dropout,\n",
    "        normalization='batch' if use_batch_norm else 'none'\n",
    "    )\n",
    "    \n",
    "    # Create the model\n",
    "    model = create_lightning_custom(\n",
    "        node_features=NUM_NODE_FEATS,\n",
    "        edge_features=NUM_EDGE_FEATS,\n",
    "        gnn_config=gnn_config,\n",
    "        pooling_config=pooling_config,\n",
    "        regressor_config=regressor_config,\n",
    "        global_dropout=global_dropout,\n",
    "        use_batch_norm=use_batch_norm,\n",
    "        \n",
    "        # Target normalization\n",
    "        target_mean=data_info['target_mean'],\n",
    "        target_std=data_info['target_std'],\n",
    "        \n",
    "        # Optimization\n",
    "        optimizer=optimizer,\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        gradient_clip_val=gradient_clip_val,\n",
    "        \n",
    "        # Monitoring\n",
    "        monitor_metric='val_mae',\n",
    "        log_embeddings=False,  # Disable for performance\n",
    "        log_predictions=False,  # Disable for performance\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# üéØ Optimized Objective Function with Enhanced W&B Support\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Robust objective function for Optuna optimization with W&B logging.\n",
    "    Handles entity permission issues and provides detailed error information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Suggest hyperparameters\n",
    "        num_layers = trial.suggest_int('num_layers', 2, 6)\n",
    "        hidden_dim = trial.suggest_categorical('hidden_dim', [64, 128, 256, 512])\n",
    "        dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "        \n",
    "        # Create trial config\n",
    "        trial_config = {\n",
    "            'num_layers': num_layers,\n",
    "            'hidden_dim': hidden_dim,\n",
    "            'dropout': dropout,\n",
    "            'learning_rate': learning_rate,\n",
    "            'optimizer': 'AdamW',\n",
    "            'trial_number': trial.number\n",
    "        }\n",
    "        \n",
    "        # Initialize W&B with enhanced error handling\n",
    "        wandb_run = None\n",
    "        try:\n",
    "            print(f\"üîÑ Trial {trial.number}: Initializing W&B...\")\n",
    "            \n",
    "            # Validate entity before run creation\n",
    "            if not WANDB_ENTITY:\n",
    "                print(\"‚ö†Ô∏è WANDB_ENTITY not set, using default entity\")\n",
    "                wandb_run = wandb.init(\n",
    "                    project=PROJECT_NAME,\n",
    "                    config=trial_config,\n",
    "                    name=f\"trial_{trial.number}\",\n",
    "                    tags=[\"optuna\", \"hyperparameter_tuning\"],\n",
    "                    reinit=True\n",
    "                )\n",
    "            else:\n",
    "                print(f\"üè¢ Using entity: {WANDB_ENTITY}\")\n",
    "                wandb_run = wandb.init(\n",
    "                    project=PROJECT_NAME,\n",
    "                    entity=WANDB_ENTITY,\n",
    "                    config=trial_config,\n",
    "                    name=f\"trial_{trial.number}\",\n",
    "                    tags=[\"optuna\", \"hyperparameter_tuning\"],\n",
    "                    reinit=True\n",
    "                )\n",
    "            \n",
    "            print(f\"‚úÖ W&B run initialized: {wandb_run.id}\")\n",
    "            \n",
    "        except Exception as wandb_error:\n",
    "            print(f\"‚ö†Ô∏è W&B initialization failed: {wandb_error}\")\n",
    "            error_msg = str(wandb_error).lower()\n",
    "            \n",
    "            if \"permission denied\" in error_msg or \"403\" in error_msg:\n",
    "                print(f\"\\nüö® 403 Permission Denied Error Detected!\")\n",
    "                print(f\"   Current entity: {WANDB_ENTITY}\")\n",
    "                print(f\"   This usually means the entity name is incorrect.\")\n",
    "                print(f\"   Solution: Update WANDB_ENTITY to your organization name\")\n",
    "                \n",
    "                # Try without entity as fallback\n",
    "                print(f\"   Attempting fallback without entity...\")\n",
    "                try:\n",
    "                    wandb_run = wandb.init(\n",
    "                        project=PROJECT_NAME,\n",
    "                        config=trial_config,\n",
    "                        name=f\"trial_{trial.number}_fallback\",\n",
    "                        tags=[\"optuna\", \"hyperparameter_tuning\", \"entity_fallback\"],\n",
    "                        reinit=True\n",
    "                    )\n",
    "                    print(f\"‚úÖ Fallback W&B run successful: {wandb_run.id}\")\n",
    "                except Exception as fallback_error:\n",
    "                    print(f\"‚ùå Fallback also failed: {fallback_error}\")\n",
    "                    wandb_run = None\n",
    "            else:\n",
    "                wandb_run = None\n",
    "        \n",
    "        # Setup model and data (simulated for now)\n",
    "        print(f\"üèóÔ∏è Trial {trial.number}: Building model with config: {trial_config}\")\n",
    "        \n",
    "        # Simulate training (replace with actual model training)\n",
    "        import random\n",
    "        import time\n",
    "        \n",
    "        # Simulate epochs\n",
    "        best_val_loss = float('inf')\n",
    "        for epoch in range(3):  # Reduced for faster testing\n",
    "            # Simulate training metrics\n",
    "            train_loss = random.uniform(0.1, 1.0) * (0.9 ** epoch)\n",
    "            val_loss = random.uniform(0.1, 1.0) * (0.9 ** epoch)\n",
    "            \n",
    "            metrics = {\n",
    "                'epoch': epoch,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'learning_rate': learning_rate\n",
    "            }\n",
    "            \n",
    "            # Log to W&B if available\n",
    "            if wandb_run:\n",
    "                try:\n",
    "                    wandb_run.log(metrics)\n",
    "                except Exception as log_error:\n",
    "                    print(f\"‚ö†Ô∏è W&B logging failed: {log_error}\")\n",
    "            \n",
    "            # Report to Optuna\n",
    "            trial.report(val_loss, epoch)\n",
    "            \n",
    "            # Update best validation loss\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "            \n",
    "            # Check for pruning\n",
    "            if trial.should_prune():\n",
    "                print(f\"üî• Trial {trial.number} pruned at epoch {epoch}\")\n",
    "                if wandb_run:\n",
    "                    wandb_run.log({'pruned': True, 'pruned_epoch': epoch})\n",
    "                    wandb_run.finish()\n",
    "                raise optuna.TrialPruned()\n",
    "            \n",
    "            time.sleep(0.1)  # Small delay to simulate training\n",
    "        \n",
    "        # Log final results\n",
    "        if wandb_run:\n",
    "            try:\n",
    "                wandb_run.log({\n",
    "                    'final_val_loss': best_val_loss,\n",
    "                    'trial_completed': True\n",
    "                })\n",
    "                wandb_run.finish()\n",
    "            except Exception as log_error:\n",
    "                print(f\"‚ö†Ô∏è Final W&B logging failed: {log_error}\")\n",
    "        \n",
    "        print(f\"‚úÖ Trial {trial.number} completed with val_loss: {best_val_loss:.4f}\")\n",
    "        return best_val_loss\n",
    "        \n",
    "    except optuna.TrialPruned:\n",
    "        raise  # Re-raise pruned trials\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Trial {trial.number} failed: {e}\")\n",
    "        if wandb_run:\n",
    "            try:\n",
    "                wandb_run.log({'error': str(e), 'trial_failed': True})\n",
    "                wandb_run.finish()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Return a high loss value for failed trials instead of crashing\n",
    "        return float('inf')\n",
    "\n",
    "print(\"‚úÖ Multi-objective optimization setup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d02e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> Tuple[float, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Multi-objective optimization function for Optuna.\n",
    "    \n",
    "    Objectives to minimize:\n",
    "    1. Validation MAE (primary objective)\n",
    "    2. Memory consumption (MB)\n",
    "    3. Training time (minutes)\n",
    "    4. Inverse throughput (to maximize throughput)\n",
    "    5. Latency (ms per sample)\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of objectives to minimize\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reset system monitor for this trial\n",
    "    system_monitor.reset()\n",
    "    \n",
    "    try:\n",
    "        # Create model with trial hyperparameters\n",
    "        model = create_model_with_config(trial, data_info)\n",
    "        \n",
    "        # Initialize W&B logging for this trial if available\n",
    "        logger = None\n",
    "        if WANDB_AVAILABLE and WANDB_API_KEY:\n",
    "            try:\n",
    "                # Try to initialize W&B with better error handling\n",
    "                logger = WandbLogger(\n",
    "                    project=WANDB_PROJECT,\n",
    "                    entity=WANDB_ENTITY,\n",
    "                    name=f\"trial_{trial.number}\",\n",
    "                    group=\"optuna_optimization\",\n",
    "                    tags=[\"multi_objective\", \"zinc\", \"graph_regression\"],\n",
    "                    config={\n",
    "                        **{f\"hp_{k}\": v for k, v in trial.params.items()},\n",
    "                        **CONFIG,\n",
    "                        \"trial_number\": trial.number,\n",
    "                        \"debug_mode\": DEBUG_MODE if 'DEBUG_MODE' in globals() else False\n",
    "                    }\n",
    "                    # Note: settings parameter doesn't exist in WandbLogger\n",
    "                    # W&B settings are controlled via environment variables\n",
    "                )\n",
    "            except Exception as e:\n",
    "                error_msg = str(e).lower()\n",
    "                if \"permission denied\" in error_msg or \"upsert bucket\" in error_msg:\n",
    "                    print(f\"‚ö†Ô∏è W&B authentication issue, continuing without logging: {e}\")\n",
    "                elif \"api_key\" in error_msg or \"login\" in error_msg:\n",
    "                    print(f\"‚ö†Ô∏è W&B API key issue, continuing without logging: {e}\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è W&B logger failed to initialize: {e}\")\n",
    "                logger = None\n",
    "        \n",
    "        # Set up callbacks - FIXED: Create fresh instances for each trial\n",
    "        callbacks = []\n",
    "        \n",
    "        # Add Early Stopping - create new instance each time\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_mae',\n",
    "            patience=CONFIG['early_stopping_patience'],\n",
    "            mode='min',\n",
    "            verbose=False\n",
    "        )\n",
    "        callbacks.append(early_stopping)\n",
    "        \n",
    "        # Add Learning Rate Monitor - create new instance each time\n",
    "        lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "        callbacks.append(lr_monitor)\n",
    "        \n",
    "        # Skip Optuna pruning callback to avoid \"Expected a parent\" error\n",
    "        # This callback can cause issues with PyTorch Lightning's callback system\n",
    "        # Manual pruning can be implemented if needed\n",
    "        \n",
    "        # Create trainer with simplified configuration\n",
    "        trainer_kwargs = {\n",
    "            'max_epochs': CONFIG['max_epochs'],\n",
    "            'accelerator': 'auto',\n",
    "            'devices': 1,\n",
    "            'logger': logger,\n",
    "            'callbacks': callbacks,\n",
    "            'enable_progress_bar': False,  # Disable for cleaner output\n",
    "            'enable_checkpointing': False,  # Disable to save space\n",
    "            'val_check_interval': CONFIG['val_check_interval'],\n",
    "            'log_every_n_steps': CONFIG['log_every_n_steps'],\n",
    "            'deterministic': True,\n",
    "        }\n",
    "        \n",
    "        # Add gradient clipping if model supports it\n",
    "        try:\n",
    "            if hasattr(model, 'hparams') and hasattr(model.hparams, 'gradient_clip_val'):\n",
    "                trainer_kwargs['gradient_clip_val'] = model.hparams.gradient_clip_val\n",
    "        except Exception:\n",
    "            pass  # Skip gradient clipping if not available\n",
    "        \n",
    "        trainer = Trainer(**trainer_kwargs)\n",
    "        \n",
    "        # Start monitoring\n",
    "        print(f\"\\nüöÄ Starting trial {trial.number}\")\n",
    "        trial_start_time = time.time()\n",
    "        \n",
    "        # Start system monitoring manually\n",
    "        system_monitor.start_monitoring()\n",
    "        \n",
    "        # Train the model\n",
    "        trainer.fit(\n",
    "            model,\n",
    "            train_dataloaders=data_info['train_loader'],\n",
    "            val_dataloaders=data_info['val_loader']\n",
    "        )\n",
    "        \n",
    "        # Record training completion for monitoring\n",
    "        training_end_time = time.time()\n",
    "        training_duration = training_end_time - trial_start_time\n",
    "        \n",
    "        # Estimate samples processed (rough calculation)\n",
    "        num_epochs = trainer.current_epoch + 1\n",
    "        samples_per_epoch = data_info['num_train_samples'] + data_info['num_val_samples'] \n",
    "        total_samples = num_epochs * samples_per_epoch\n",
    "        system_monitor.samples_processed = total_samples\n",
    "        system_monitor.epoch_count = num_epochs\n",
    "        \n",
    "        # Get final validation metrics\n",
    "        try:\n",
    "            val_results = trainer.validate(model, data_info['val_loader'], verbose=False)\n",
    "            val_mae = val_results[0]['val_mae']\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not get validation results: {e}\")\n",
    "            # Try to get from callback metrics\n",
    "            val_mae = trainer.callback_metrics.get('val_mae', float('inf'))\n",
    "            if val_mae == float('inf'):\n",
    "                print(\"‚ùå Could not retrieve validation MAE\")\n",
    "                raise optuna.TrialPruned()\n",
    "        \n",
    "        # Get system metrics\n",
    "        system_metrics = system_monitor.get_metrics()\n",
    "        \n",
    "        # Calculate objectives with fallbacks\n",
    "        memory_consumption = max(0, system_metrics.get('memory_consumption_mb', 0))\n",
    "        training_time = max(0.01, system_metrics.get('training_time_minutes', 0.01))  # Minimum 0.01 to avoid division by zero\n",
    "        throughput = max(1e-6, system_metrics.get('throughput_samples_per_sec', 1e-6))\n",
    "        latency = system_metrics.get('latency_ms_per_sample', float('inf'))\n",
    "        \n",
    "        # Inverse throughput (to minimize for maximizing throughput)\n",
    "        inverse_throughput = 1.0 / throughput\n",
    "        \n",
    "        # Sanity checks for objectives\n",
    "        if not torch.isfinite(torch.tensor(val_mae)):\n",
    "            print(f\"‚ùå Invalid validation MAE: {val_mae}\")\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        # Cap extreme values to prevent optimizer confusion\n",
    "        memory_consumption = min(memory_consumption, 10000)  # Max 10GB\n",
    "        training_time = min(training_time, 120)  # Max 2 hours\n",
    "        inverse_throughput = min(inverse_throughput, 1000)  # Min 0.001 throughput\n",
    "        latency = min(latency, 10000)  # Max 10 seconds per sample\n",
    "        \n",
    "        # Log trial results\n",
    "        trial_results = {\n",
    "            'val_mae': float(val_mae),\n",
    "            'memory_consumption_mb': memory_consumption,\n",
    "            'training_time_minutes': training_time,\n",
    "            'throughput_samples_per_sec': throughput,\n",
    "            'latency_ms_per_sample': latency,\n",
    "            'inverse_throughput': inverse_throughput,\n",
    "            'model_parameters': sum(p.numel() for p in model.parameters()),\n",
    "            'trial_duration_minutes': (time.time() - trial_start_time) / 60,\n",
    "            'epochs_completed': system_metrics.get('epochs_completed', 0),\n",
    "        }\n",
    "        \n",
    "        print(f\"üìä Trial {trial.number} Results:\")\n",
    "        for key, value in trial_results.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"  {key}: {value:.4f}\")\n",
    "            else:\n",
    "                print(f\"  {key}: {value}\")\n",
    "        \n",
    "        # Log to W&B if available\n",
    "        if logger is not None:\n",
    "            try:\n",
    "                logger.experiment.log({\n",
    "                    \"trial_objectives/val_mae\": val_mae,\n",
    "                    \"trial_objectives/memory_consumption_mb\": memory_consumption,\n",
    "                    \"trial_objectives/training_time_minutes\": training_time,\n",
    "                    \"trial_objectives/inverse_throughput\": inverse_throughput,\n",
    "                    \"trial_objectives/latency_ms\": latency,\n",
    "                    **{f\"trial_results/{k}\": v for k, v in trial_results.items()},\n",
    "                    **{f\"system_metrics/{k}\": v for k, v in system_metrics.items()},\n",
    "                })\n",
    "                \n",
    "                # Finish W&B run\n",
    "                wandb.finish()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Failed to log to W&B: {e}\")\n",
    "        \n",
    "        # Return objectives to minimize\n",
    "        objectives = (float(val_mae), memory_consumption, training_time, inverse_throughput, latency)\n",
    "        \n",
    "        # Final validation of objectives\n",
    "        if any(not torch.isfinite(torch.tensor(obj)) for obj in objectives):\n",
    "            print(f\"‚ùå Invalid objectives detected: {objectives}\")\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        return objectives\n",
    "        \n",
    "    except optuna.TrialPruned:\n",
    "        print(f\"‚úÇÔ∏è Trial {trial.number} was pruned\")\n",
    "        raise  # Re-raise pruning exception\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Trial {trial.number} failed: {str(e)}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        \n",
    "        # Log error details for debugging\n",
    "        import traceback\n",
    "        error_details = traceback.format_exc()\n",
    "        print(f\"Error traceback: {error_details}\")\n",
    "        \n",
    "        # Clean up W&B if needed\n",
    "        if 'logger' in locals() and logger is not None:\n",
    "            try:\n",
    "                # Properly finish W&B run\n",
    "                if hasattr(logger, 'experiment'):\n",
    "                    logger.experiment.finish()\n",
    "                wandb.finish()\n",
    "            except Exception as cleanup_error:\n",
    "                print(f\"‚ö†Ô∏è W&B cleanup failed: {cleanup_error}\")\n",
    "                # Try alternative cleanup\n",
    "                try:\n",
    "                    wandb.finish(exit_code=1)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "        # Return poor objectives for failed trials\n",
    "        return (float('inf'), float('inf'), float('inf'), float('inf'), float('inf'))\n",
    "    \n",
    "    finally:\n",
    "        # Clean up GPU memory and resources\n",
    "        try:\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "            # Force cleanup of Lightning trainer and callbacks\n",
    "            if 'trainer' in locals():\n",
    "                del trainer\n",
    "            if 'model' in locals():\n",
    "                del model\n",
    "            if 'callbacks' in locals():\n",
    "                del callbacks\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Cleanup warning: {e}\")\n",
    "\n",
    "print(\"‚úÖ Enhanced objective function with callback fix defined!\")\n",
    "\n",
    "# Test objective function setup (without running a full trial)\n",
    "try:\n",
    "    print(\"üß™ Testing objective function setup...\")\n",
    "    # This just tests that we can create the function without errors\n",
    "    print(\"‚úÖ Objective function setup test passed!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Objective function setup test failed: {e}\")\n",
    "    print(\"Please check your configuration before proceeding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47399744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Run Optuna Study\n",
    "\n",
    "def create_optuna_study():\n",
    "    \"\"\"Create Optuna study with multi-objective optimization.\"\"\"\n",
    "    \n",
    "    # Configure storage\n",
    "    storage = None\n",
    "    if OPTUNA_DB_URL:\n",
    "        try:\n",
    "            storage = optuna.storages.RDBStorage(\n",
    "                url=OPTUNA_DB_URL,\n",
    "                engine_kwargs={\"pool_pre_ping\": True}\n",
    "            )\n",
    "            print(\"‚úÖ Connected to remote Optuna database\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to connect to remote database: {e}\")\n",
    "            print(\"üìÅ Using local SQLite storage\")\n",
    "            storage = optuna.storages.RDBStorage(\"sqlite:///optuna_study.db\")\n",
    "    else:\n",
    "        print(\"üìÅ Using local SQLite storage\")\n",
    "        storage = optuna.storages.RDBStorage(\"sqlite:///optuna_study.db\")\n",
    "    \n",
    "    # Create multi-objective study\n",
    "    study = optuna.create_study(\n",
    "        study_name=STUDY_NAME,\n",
    "        storage=storage,\n",
    "        directions=['minimize'] * 5,  # All objectives to minimize\n",
    "        sampler=optuna.samplers.NSGAIISampler(population_size=20),\n",
    "        pruner=optuna.pruners.MedianPruner(\n",
    "            n_startup_trials=5,\n",
    "            n_warmup_steps=10,\n",
    "            interval_steps=5\n",
    "        ),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    \n",
    "    return study\n",
    "\n",
    "def run_optimization():\n",
    "    \"\"\"Run the multi-objective hyperparameter optimization.\"\"\"\n",
    "    \n",
    "    print(\"üéØ Starting Multi-Objective Hyperparameter Optimization\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Objectives to minimize:\")\n",
    "    print(f\"  1. Validation MAE (primary)\")\n",
    "    print(f\"  2. Memory consumption (MB)\")\n",
    "    print(f\"  3. Training time (minutes)\")\n",
    "    print(f\"  4. Inverse throughput (maximize throughput)\")\n",
    "    print(f\"  5. Latency per sample (ms)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create study\n",
    "    study = create_optuna_study()\n",
    "    \n",
    "    # Set timeout based on Kaggle constraints\n",
    "    timeout_seconds = CONFIG['timeout_hours'] * 3600\n",
    "    \n",
    "    try:\n",
    "        # Run optimization\n",
    "        study.optimize(\n",
    "            objective,\n",
    "            n_trials=CONFIG['num_trials'],\n",
    "            timeout=timeout_seconds,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\nüéâ Optimization completed!\")\n",
    "        \n",
    "        # Analyze results\n",
    "        analyze_optimization_results(study)\n",
    "        \n",
    "        return study\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è Optimization interrupted by user\")\n",
    "        return study\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Optimization failed: {str(e)}\")\n",
    "        return study\n",
    "\n",
    "def analyze_optimization_results(study: optuna.Study):\n",
    "    \"\"\"Analyze and display optimization results.\"\"\"\n",
    "    \n",
    "    print(\"\\nüìä Optimization Results Analysis\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Get all trials\n",
    "    trials = study.trials\n",
    "    completed_trials = [t for t in trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    \n",
    "    print(f\"Total trials: {len(trials)}\")\n",
    "    print(f\"Completed trials: {len(completed_trials)}\")\n",
    "    print(f\"Pruned trials: {len([t for t in trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "    print(f\"Failed trials: {len([t for t in trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
    "    \n",
    "    if not completed_trials:\n",
    "        print(\"‚ö†Ô∏è No completed trials to analyze\")\n",
    "        return\n",
    "    \n",
    "    # Find Pareto front (best trade-offs)\n",
    "    pareto_trials = []\n",
    "    for trial in completed_trials:\n",
    "        is_dominated = False\n",
    "        for other_trial in completed_trials:\n",
    "            if trial == other_trial:\n",
    "                continue\n",
    "            # Check if other_trial dominates trial\n",
    "            if all(other_val <= trial_val for other_val, trial_val in \n",
    "                   zip(other_trial.values, trial.values)) and \\\n",
    "               any(other_val < trial_val for other_val, trial_val in \n",
    "                   zip(other_trial.values, trial.values)):\n",
    "                is_dominated = True\n",
    "                break\n",
    "        if not is_dominated:\n",
    "            pareto_trials.append(trial)\n",
    "    \n",
    "    print(f\"\\nüèÜ Pareto-optimal solutions: {len(pareto_trials)}\")\n",
    "    \n",
    "    # Display best solutions for each objective\n",
    "    objective_names = [\n",
    "        \"Validation MAE\",\n",
    "        \"Memory Consumption (MB)\", \n",
    "        \"Training Time (min)\",\n",
    "        \"Inverse Throughput\",\n",
    "        \"Latency (ms)\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nü•á Best solutions for each objective:\")\n",
    "    for i, obj_name in enumerate(objective_names):\n",
    "        best_trial = min(completed_trials, key=lambda t: t.values[i])\n",
    "        print(f\"\\n{obj_name}:\")\n",
    "        print(f\"  Value: {best_trial.values[i]:.4f}\")\n",
    "        print(f\"  Trial: {best_trial.number}\")\n",
    "        print(f\"  Key params: {dict(list(best_trial.params.items())[:3])}\")\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame([\n",
    "        {\n",
    "            'trial_number': trial.number,\n",
    "            'val_mae': trial.values[0],\n",
    "            'memory_mb': trial.values[1], \n",
    "            'training_time_min': trial.values[2],\n",
    "            'inverse_throughput': trial.values[3],\n",
    "            'latency_ms': trial.values[4],\n",
    "            **trial.params\n",
    "        }\n",
    "        for trial in completed_trials\n",
    "    ])\n",
    "    \n",
    "    results_file = \"optuna_results.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f\"\\nüíæ Results saved to {results_file}\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\nüìà Summary Statistics:\")\n",
    "    for i, obj_name in enumerate(objective_names):\n",
    "        values = [trial.values[i] for trial in completed_trials]\n",
    "        print(f\"{obj_name}: min={min(values):.4f}, max={max(values):.4f}, mean={np.mean(values):.4f}\")\n",
    "\n",
    "print(\"‚úÖ Optimization functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f587242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ ZINC Graph Regression Multi-Objective Hyperparameter Optimization\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müéØ ZINC Graph Regression Multi-Objective Hyperparameter Optimization\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEnvironment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mKaggle GPU\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mtorch.cuda.is_available()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mCPU\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset: ZINC (Small subset)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMax trials: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG[\u001b[33m'\u001b[39m\u001b[33mnum_trials\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# üöÄ RUN OPTIMIZATION\n",
    "# This is the main execution cell\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üéØ ZINC Graph Regression Multi-Objective Hyperparameter Optimization\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Environment: {'Kaggle GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "    print(f\"Dataset: ZINC (Small subset)\")\n",
    "    print(f\"Max trials: {CONFIG['num_trials']}\")\n",
    "    print(f\"Timeout: {CONFIG['timeout_hours']} hours\")\n",
    "    print(f\"Mode: {'DEBUG' if DEBUG_MODE else 'PRODUCTION'}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Pre-execution validation\n",
    "    try:\n",
    "        print(\"\\nüîç Pre-execution validation...\")\n",
    "        \n",
    "        # Check data is loaded\n",
    "        if 'data_info' not in locals():\n",
    "            raise RuntimeError(\"Data not loaded. Please run data preparation cell first.\")\n",
    "        \n",
    "        # Check system monitor is ready\n",
    "        if 'system_monitor' not in locals():\n",
    "            raise RuntimeError(\"System monitor not initialized. Please run system monitor cell first.\")\n",
    "        \n",
    "        # Quick model creation test\n",
    "        print(\"üß™ Testing model creation...\")\n",
    "        \n",
    "        # Create a simple dummy trial for testing model creation\n",
    "        class DummyTrial:\n",
    "            def __init__(self, params):\n",
    "                self.params = params\n",
    "                self.number = 0\n",
    "            def suggest_categorical(self, name, choices): return self.params[name]\n",
    "            def suggest_int(self, name, low, high): return self.params[name]\n",
    "            def suggest_float(self, name, low, high, log=False): return self.params[name]\n",
    "        \n",
    "        test_params = {\n",
    "            'hidden_dim': 128,\n",
    "            'num_layers': 3,\n",
    "            'layer_name': 'GINEConv',\n",
    "            'dropout_rate': 0.1,\n",
    "            'global_dropout': 0.1,\n",
    "            'pooling_type': 'mean',\n",
    "            'regressor_type': 'mlp',\n",
    "            'regressor_choice': 1,  # This will give [hidden_dim, hidden_dim//2]\n",
    "            'mlp_dropout': 0.1,\n",
    "            'optimizer': 'adamw',\n",
    "            'lr': 1e-3,\n",
    "            'weight_decay': 1e-4,\n",
    "            'lr_scheduler': 'cosine',\n",
    "            'use_batch_norm': True,\n",
    "            'gradient_clip_val': 1.0,\n",
    "        }\n",
    "        \n",
    "        dummy_trial = DummyTrial(test_params)\n",
    "        test_model = create_model_with_config(dummy_trial, data_info)\n",
    "        del test_model, dummy_trial, test_params\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "        print(\"‚úÖ Pre-execution validation passed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Pre-execution validation failed: {e}\")\n",
    "        print(\"Please check your setup and try again.\")\n",
    "        raise\n",
    "    \n",
    "    # Initialize W&B project if available\n",
    "    project_run = None\n",
    "    if WANDB_AVAILABLE and WANDB_API_KEY:\n",
    "        try:\n",
    "            project_run = wandb.init(\n",
    "                project=WANDB_PROJECT,\n",
    "                entity=WANDB_ENTITY,\n",
    "                name=\"multi_objective_optimization_master\",\n",
    "                job_type=\"hyperparameter_search\",\n",
    "                tags=[\"optuna\", \"multi_objective\", \"zinc\", \"graph_regression\"],\n",
    "                config={\n",
    "                    **CONFIG,\n",
    "                    \"debug_mode\": DEBUG_MODE,\n",
    "                    \"total_dataset_size\": data_info['num_train_samples'] + data_info['num_val_samples'],\n",
    "                    \"batch_size\": BATCH_SIZE if 'BATCH_SIZE' in locals() else 32,\n",
    "                }\n",
    "            )\n",
    "            print(\"‚úÖ W&B master experiment tracking initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è W&B master initialization failed: {e}\")\n",
    "    \n",
    "    # Run the optimization with comprehensive error handling\n",
    "    try:\n",
    "        study = run_optimization()\n",
    "        optimization_successful = True\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è Optimization interrupted by user\")\n",
    "        study = None\n",
    "        optimization_successful = False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Optimization failed with error: {str(e)}\")\n",
    "        import traceback\n",
    "        print(f\"Error details: {traceback.format_exc()}\")\n",
    "        study = None\n",
    "        optimization_successful = False\n",
    "    \n",
    "    # Analyze results if we have any\n",
    "    best_trial_info = None\n",
    "    if study and study.trials:\n",
    "        try:\n",
    "            print(\"\\nüß™ Evaluating best models on test set...\")\n",
    "            \n",
    "            completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "            \n",
    "            if completed_trials:\n",
    "                # Get best trial for primary objective (validation MAE)\n",
    "                best_mae_trial = min(completed_trials, key=lambda t: t.values[0])\n",
    "                \n",
    "                print(f\"\\nüèÜ Best model (lowest validation MAE):\")\n",
    "                print(f\"Trial: {best_mae_trial.number}\")\n",
    "                print(f\"Validation MAE: {best_mae_trial.values[0]:.4f}\")\n",
    "                print(f\"Memory consumption: {best_mae_trial.values[1]:.1f} MB\")\n",
    "                print(f\"Training time: {best_mae_trial.values[2]:.2f} minutes\")\n",
    "                print(f\"Throughput: {1.0/best_mae_trial.values[3]:.1f} samples/sec\")\n",
    "                print(f\"Latency: {best_mae_trial.values[4]:.2f} ms/sample\")\n",
    "                \n",
    "                # Store best trial info for summary (validation-based only)\n",
    "                print(f\"\\n‚úÖ Best hyperparameters identified based on validation performance\")\n",
    "                print(f\"üìù Note: Test set is reserved for final evaluation after optimization\")\n",
    "                \n",
    "                # Calculate model parameters from the best trial\n",
    "                try:\n",
    "                    dummy_trial = DummyTrial(best_mae_trial.params)\n",
    "                    temp_model = create_model_with_config(dummy_trial, data_info)\n",
    "                    model_params = sum(p.numel() for p in temp_model.parameters())\n",
    "                    del temp_model, dummy_trial\n",
    "                    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Could not calculate model parameters: {e}\")\n",
    "                    model_params = 0\n",
    "                \n",
    "                # Store best trial info for summary (no test results)\n",
    "                best_trial_info = {\n",
    "                    \"trial_number\": best_mae_trial.number,\n",
    "                    \"val_mae\": best_mae_trial.values[0],\n",
    "                    \"memory_mb\": best_mae_trial.values[1],\n",
    "                    \"training_time_min\": best_mae_trial.values[2],\n",
    "                    \"model_parameters\": model_params,\n",
    "                    \"params\": best_mae_trial.params\n",
    "                }\n",
    "                \n",
    "                # Log validation results to W&B\n",
    "                if project_run is not None:\n",
    "                    try:\n",
    "                        project_run.log({\n",
    "                            \"best_model/val_mae\": best_mae_trial.values[0],\n",
    "                            \"best_model/memory_consumption_mb\": best_mae_trial.values[1],\n",
    "                            \"best_model/training_time_minutes\": best_mae_trial.values[2],\n",
    "                            \"best_model/model_parameters\": model_params,\n",
    "                            **{f\"best_model/hp_{k}\": v for k, v in best_mae_trial.params.items()},\n",
    "                        })\n",
    "                        print(\"‚úÖ Best model validation results logged to W&B\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ö†Ô∏è Failed to log results to W&B: {e}\")\n",
    "                \n",
    "                print(\"\\n‚úÖ Hyperparameter optimization analysis completed!\")\n",
    "                print(\"üîí Test set remains untouched for unbiased final evaluation\")\n",
    "                \n",
    "            else:\n",
    "                print(\"‚ùå No completed trials to evaluate\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Results analysis failed: {e}\")\n",
    "            import traceback\n",
    "            print(f\"Error details: {traceback.format_exc()}\")\n",
    "    \n",
    "    # Final cleanup and summary\n",
    "    try:\n",
    "        # Finish W&B logging\n",
    "        if project_run is not None:\n",
    "            wandb.finish()\n",
    "        \n",
    "        print(\"\\nüìã FINAL SUMMARY:\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"- Dataset: ZINC (training: {data_info['num_train_samples']}, validation: {data_info['num_val_samples']}, test: {data_info['num_test_samples']})\")\n",
    "        print(f\"- Optimization: {'‚úÖ Completed' if optimization_successful else '‚ùå Failed/Interrupted'}\")\n",
    "        print(f\"- Total trials: {len(study.trials) if study else 0}\")\n",
    "        print(f\"- Completed trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]) if study else 0}\")\n",
    "        print(f\"- Results saved: {'‚úÖ optuna_results.csv' if study and study.trials else '‚ùå No results to save'}\")\n",
    "        print(f\"- W&B logging: {'‚úÖ' if WANDB_AVAILABLE and WANDB_API_KEY else '‚ùå'}\")\n",
    "        print(f\"- Remote database: {'‚úÖ' if OPTUNA_DB_URL else '‚ùå (local SQLite used)'}\")\n",
    "        \n",
    "        if best_trial_info:\n",
    "            print(f\"\\nüèÜ BEST MODEL SUMMARY (Validation-Based):\")\n",
    "            print(f\"- Trial: {best_trial_info['trial_number']}\")\n",
    "            print(f\"- Validation MAE: {best_trial_info['val_mae']:.4f}\")\n",
    "            print(f\"- Architecture: {best_trial_info['params']['layer_name']}-{best_trial_info['params']['hidden_dim']}-{best_trial_info['params']['num_layers']}\")\n",
    "            print(f\"- Parameters: {best_trial_info['model_parameters']:,}\")\n",
    "            print(f\"- Memory: {best_trial_info['memory_mb']:.1f} MB\")\n",
    "            print(f\"- Training time: {best_trial_info['training_time_min']:.2f} min\")\n",
    "            print(f\"üîí Test performance: Reserved for unbiased final evaluation\")\n",
    "        \n",
    "        print(\"\\nüéâ Multi-objective hyperparameter optimization completed!\")\n",
    "        print(\"Check the CSV file and W&B dashboard for detailed results.\")\n",
    "        print(\"\\nüîí IMPORTANT: Test set preserved for unbiased final evaluation!\")\n",
    "        print(\"   Use the best hyperparameters to train a final model and\")\n",
    "        print(\"   evaluate it ONCE on the test set for publication results.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Final cleanup/summary failed: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Notebook execution completed. Thank you for using ACA GraphML!\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c63eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç W&B Entity Diagnostic\n",
    "# This cell helps identify the correct entity name to use\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "    api = wandb.Api()\n",
    "    user = api.viewer\n",
    "    \n",
    "    print(\"üîç W&B Account Information:\")\n",
    "    print(f\"   Personal Username: {user.username}\")\n",
    "    print(f\"   Current Entity Setting: {WANDB_ENTITY if WANDB_ENTITY else 'Not set'}\")\n",
    "    \n",
    "    # List available entities (organizations/teams)\n",
    "    print(f\"\\nüìã Available Entities for {user.username}:\")\n",
    "    \n",
    "    # Get user teams/organizations\n",
    "    try:\n",
    "        # Try to list projects to see available entities\n",
    "        projects = api.projects()  # This will show projects from default entity\n",
    "        print(f\"   Default entity projects found: {len(list(projects))}\")\n",
    "        \n",
    "        # Check if user has team access\n",
    "        print(f\"\\nüí° Instructions:\")\n",
    "        print(f\"   1. Go to https://wandb.ai and check your dashboard URL\")\n",
    "        print(f\"   2. The entity name appears in URLs like: wandb.ai/[ENTITY]/[PROJECT]\")\n",
    "        print(f\"   3. Use the organization/team name, not your personal username '{user.username}'\")\n",
    "        print(f\"   4. Update your Kaggle secret 'WANDB_ENTITY' with the correct entity name\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Error listing entities: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå W&B diagnostic failed: {e}\")\n",
    "    print(\"Make sure W&B is logged in first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0415a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß W&B DEBUGGING AND SETUP\n",
    "# Run this cell if you're having W&B authentication issues\n",
    "\n",
    "def diagnose_wandb_issues():\n",
    "    \"\"\"Diagnose common W&B authentication problems.\"\"\"\n",
    "    print(\"üîç W&B Diagnostic Check\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check if wandb is installed\n",
    "    try:\n",
    "        import wandb\n",
    "        print(\"‚úÖ W&B library is installed\")\n",
    "        print(f\"   Version: {wandb.__version__}\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå W&B library not found\")\n",
    "        print(\"üí° Install with: !pip install wandb\")\n",
    "        return\n",
    "    \n",
    "    # Check if API key is configured\n",
    "    if WANDB_API_KEY:\n",
    "        print(\"‚úÖ W&B API key is configured\")\n",
    "        print(f\"   Key preview: {WANDB_API_KEY[:8]}...\")\n",
    "    else:\n",
    "        print(\"‚ùå W&B API key not configured\")\n",
    "        print(\"üí° Set WANDB_API_KEY in Kaggle secrets\")\n",
    "        return\n",
    "    \n",
    "    # Test API key validity\n",
    "    try:\n",
    "        print(\"\\nüß™ Testing W&B API connection...\")\n",
    "        \n",
    "        # Initialize W&B in offline mode first to test\n",
    "        wandb.init(\n",
    "            mode=\"offline\",\n",
    "            project=\"test-connection\",\n",
    "            name=\"diagnostic-test\"\n",
    "        )\n",
    "        wandb.finish()\n",
    "        print(\"‚úÖ Offline mode works\")\n",
    "        \n",
    "        # Now test online mode\n",
    "        api = wandb.Api(api_key=WANDB_API_KEY)\n",
    "        user = api.viewer\n",
    "        print(f\"‚úÖ API key valid - logged in as: {user.username}\")\n",
    "        \n",
    "        # Test project access\n",
    "        try:\n",
    "            projects = list(api.projects(entity=WANDB_ENTITY))\n",
    "            print(f\"‚úÖ Can access projects for entity: {WANDB_ENTITY}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Project access issue: {e}\")\n",
    "            print(f\"üí° Check if entity '{WANDB_ENTITY}' exists and you have access\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå W&B API test failed: {e}\")\n",
    "        error_msg = str(e).lower()\n",
    "        \n",
    "        if \"permission denied\" in error_msg or \"unauthorized\" in error_msg:\n",
    "            print(\"üí° API key may be invalid or expired\")\n",
    "            print(\"   - Go to https://wandb.ai/settings\")\n",
    "            print(\"   - Generate a new API key\")\n",
    "            print(\"   - Update your Kaggle secret\")\n",
    "        elif \"network\" in error_msg or \"connection\" in error_msg:\n",
    "            print(\"üí° Network connectivity issue\")\n",
    "            print(\"   - Check internet connection\")\n",
    "            print(\"   - Try again in a few minutes\")\n",
    "        else:\n",
    "            print(\"üí° Unknown issue - check W&B status at https://status.wandb.ai\")\n",
    "\n",
    "def setup_wandb_properly():\n",
    "    \"\"\"Properly configure W&B for the optimization.\"\"\"\n",
    "    global WANDB_API_KEY, WANDB_AVAILABLE\n",
    "    \n",
    "    print(\"üîß Setting up W&B for optimization\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not WANDB_API_KEY:\n",
    "        print(\"‚ùå Cannot setup W&B - API key not configured\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Login with force refresh\n",
    "        wandb.login(key=WANDB_API_KEY, force=True)\n",
    "        \n",
    "        # Configure settings for optimization workload\n",
    "        # Note: wandb.settings.update() doesn't exist in newer versions\n",
    "        # Settings are configured via environment variables or wandb.init() parameters\n",
    "        import os\n",
    "        os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "        os.environ[\"WANDB_START_METHOD\"] = \"thread\"\n",
    "        \n",
    "        print(\"‚úÖ W&B configured successfully for optimization\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå W&B setup failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run diagnostics\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üîç Running W&B diagnostic...\")\n",
    "    diagnose_wandb_issues()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    if WANDB_API_KEY:\n",
    "        print(\"üîß Setting up W&B for optimization...\")\n",
    "        success = setup_wandb_properly()\n",
    "        if success:\n",
    "            print(\"üéâ W&B ready for optimization!\")\n",
    "        else:\n",
    "            print(\"‚ùå W&B setup failed - optimization will run without logging\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è W&B not configured - optimization will run without logging\")\n",
    "    print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
